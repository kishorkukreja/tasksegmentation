{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Text Classifier for Category detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G560667\\Category Classification\n",
      "C:\\Users\\G560667\\Category Classification\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "os.chdir('C:\\\\Users\\\\G560667\\\\Category Classification')\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_excel('Data Set-Train test.xlsx')\n",
    "df.category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>QUICK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>Home</td>\n",
       "      <td>Grout cleaning cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Home</td>\n",
       "      <td>Dryer vent cleaning cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>Home</td>\n",
       "      <td>Exterminators prices</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Home</td>\n",
       "      <td>Appliance repair cost</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>Home</td>\n",
       "      <td>Roof repair cost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    CATEGORY                     QUICK\n",
       "122     Home       Grout cleaning cost\n",
       "99      Home  Dryer vent cleaning cost\n",
       "105     Home      Exterminators prices\n",
       "67      Home     Appliance repair cost\n",
       "177     Home          Roof repair cost"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.CATEGORY\n",
    "dt_train_test=df[['CATEGORY','QUICK']]\n",
    "dt_train_test=shuffle(dt_train_test)\n",
    "dt_train_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##Extract features\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(df ['QUICK'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(255,) (255,)\n",
      "(64,) (64,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "304    Business\n",
       "113        Home\n",
       "100        Home\n",
       "25         Pets\n",
       "30      Lessons\n",
       "Name: CATEGORY, dtype: object"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cross_validation  import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "training_data=dt_train_test['QUICK']\n",
    "test_data=dt_train_test['CATEGORY']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data, test_data, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "\n",
    "X_train.head()\n",
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##Extract features\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "counts = count_vectorizer.fit_transform(X_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Lessons'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = ['Math tutor prices']\n",
    "example_counts = count_vectorizer.transform(examples)\n",
    "predictions = classifier.predict(example_counts)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  2  2  0  0  0]\n",
      " [ 0 14  3  0  0  0]\n",
      " [ 0  0 27  0  0  0]\n",
      " [ 0  3  4  3  0  0]\n",
      " [ 0  0  0  0  1  0]\n",
      " [ 0  3  2  0  0  0]]\n",
      "F1 score:  0.501709401709\n",
      "\n",
      " clasification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Business       0.00      0.00      0.00         4\n",
      "     Events       0.64      0.82      0.72        17\n",
      "       Home       0.71      1.00      0.83        27\n",
      "    Lessons       1.00      0.30      0.46        10\n",
      "       Pets       1.00      1.00      1.00         1\n",
      "   Wellness       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.64      0.70      0.63        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##Pipelining-Test Data Split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer',  CountVectorizer()),\n",
    "    ('classifier',  MultinomialNB()) ])\n",
    "\n",
    "pipeline.fit(X_train.values, y_train.values)\n",
    "pipeline.predict(examples)\n",
    "predictions=pipeline.predict(X_test)\n",
    "cm = confusion_matrix (y_test, predictions)\n",
    "print(cm)\n",
    "#print ('Accuracy: ',accuracy_score(y_test, predictions))\n",
    "print ('F1 score: ',f1_score(y_test, predictions,average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,predictions))\n",
    "#score = f1_score(y_test, predictions,pos_label=average)\n",
    "#scores.append(score)\n",
    "#plt.imshow(cm, cmap='binary')\n",
    "#plt.show()\n",
    "\n",
    "#y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  1  0  0  0]\n",
      " [ 0 14  3  0  0  0]\n",
      " [ 0  0 27  0  0  0]\n",
      " [ 0  3  2  5  0  0]\n",
      " [ 0  0  0  0  1  0]\n",
      " [ 0  3  2  0  0  0]]\n",
      "F1 score:  0.609263854425\n",
      "\n",
      " clasification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Business       1.00      0.25      0.40         4\n",
      "     Events       0.64      0.82      0.72        17\n",
      "       Home       0.77      1.00      0.87        27\n",
      "    Lessons       1.00      0.50      0.67        10\n",
      "       Pets       1.00      1.00      1.00         1\n",
      "   Wellness       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.73      0.75      0.70        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##N gram approach-Test Data Split\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
    "\n",
    "pipeline_ngram = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer(ngram_range=(1, 2))),\n",
    "    ('classifier',       MultinomialNB())\n",
    "])\n",
    "pipeline_ngram.fit(X_train.values, y_train.values)\n",
    "pipeline_ngram.predict(examples)\n",
    "predictions=pipeline_ngram.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix (y_test, predictions)\n",
    "print(cm)\n",
    "#print ('Accuracy: ',accuracy_score(y_test, predictions))\n",
    "print ('F1 score: ',f1_score(y_test, predictions,average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  4  0  0  0]\n",
      " [ 0  8  9  0  0  0]\n",
      " [ 0  0 27  0  0  0]\n",
      " [ 0  0  8  2  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0]]\n",
      "F1 score:  0.273333333333\n",
      "\n",
      " clasification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Business       0.00      0.00      0.00         4\n",
      "     Events       1.00      0.47      0.64        17\n",
      "       Home       0.50      1.00      0.67        27\n",
      "    Lessons       1.00      0.20      0.33        10\n",
      "       Pets       0.00      0.00      0.00         1\n",
      "   Wellness       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.63      0.58      0.50        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "##Ngram and TFIDF--Test Data Split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score,accuracy_score,classification_report\n",
    "\n",
    "pipeline_tfidf = Pipeline([\n",
    "    ('count_vectorizer',   CountVectorizer(stop_words='english')),\n",
    "    ('tfidf_transformer',  TfidfTransformer()),\n",
    "    ('classifier',         MultinomialNB())\n",
    "])\n",
    "\n",
    "pipeline_tfidf.fit(X_train.values, y_train.values)\n",
    "pipeline_tfidf.predict(examples)\n",
    "predictions=pipeline_tfidf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix (y_test, predictions)\n",
    "print(cm)\n",
    "#print ('Accuracy: ',accuracy_score(y_test, predictions))\n",
    "print ('F1 score: ',f1_score(y_test, predictions,average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  1  1  0  0  0]\n",
      " [ 0 14  3  0  0  0]\n",
      " [ 1  0 25  1  0  0]\n",
      " [ 0  2  0  6  1  1]\n",
      " [ 0  0  0  0  1  0]\n",
      " [ 0  0  1  0  0  4]]\n",
      "F1 score:  0.740783330876\n",
      "\n",
      " clasification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Business       0.67      0.50      0.57         4\n",
      "     Events       0.82      0.82      0.82        17\n",
      "       Home       0.83      0.93      0.88        27\n",
      "    Lessons       0.86      0.60      0.71        10\n",
      "       Pets       0.50      1.00      0.67         1\n",
      "   Wellness       0.80      0.80      0.80         5\n",
      "\n",
      "avg / total       0.82      0.81      0.81        64\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__alpha': 0.01,\n",
       " 'count_vectorizer__ngram_range': (1, 1),\n",
       " 'tfidf_transformer__use_idf': False}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.grid_search import GridSearchCV\n",
    "parameters = {'count_vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf_transformer__use_idf': (True, False),\n",
    "              'classifier__alpha': (1e-2, 1e-3),\n",
    " }\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline_tfidf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train.values, y_train.values)\n",
    "gs_clf.predict(examples)\n",
    "predictions=gs_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix (y_test, predictions)\n",
    "print(cm)\n",
    "#print ('Accuracy: ',accuracy_score(y_test, predictions))\n",
    "print ('F1 score: ',f1_score(y_test, predictions,average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,predictions))\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182                   Sink installation cost\n",
       "134             Ikea furniture assembly cost\n",
       "187                      Stump grinding cost\n",
       "219                           Bartender cost\n",
       "220               Boudoir photography prices\n",
       "161                         Pipe repair cost\n",
       "204              Washing machine repair cost\n",
       "3                        Health coach prices\n",
       "158                  Personal organizer cost\n",
       "70                       Asphalt repair cost\n",
       "181                       Shower repair cost\n",
       "0                          Career coach cost\n",
       "9                             Massage prices\n",
       "240                          Florists prices\n",
       "10                    Medical massage prices\n",
       "120     Garage doors prices and installation\n",
       "169                 Property management fees\n",
       "216      Average cost of wedding invitations\n",
       "150                    Microwave repair cost\n",
       "26      How much does it cost to board a cat\n",
       "300                  Freelance editing rates\n",
       "38                                ESL prices\n",
       "12                     Personal trainer cost\n",
       "54                         SAT tutoring cost\n",
       "64                     Ant exterminator cost\n",
       "262                       Prom makeup prices\n",
       "109                      Floor cleaning cost\n",
       "159                        Piano movers cost\n",
       "316                      Tech support prices\n",
       "255                            Open bar cost\n",
       "                       ...                  \n",
       "214                Aerial photography prices\n",
       "206                 Water heater repair cost\n",
       "308                      Printer repair cost\n",
       "238                   Family portrait prices\n",
       "45          How much do driving lessons cost\n",
       "51                Private dance lessons cost\n",
       "264           Real estate photography prices\n",
       "101                       Duct cleaning cost\n",
       "297           Criminal defense attorney cost\n",
       "176                     Roof inspection cost\n",
       "271                       Videography prices\n",
       "44                Horse riding lesson prices\n",
       "98                         Dryer repair cost\n",
       "152                  Moving companies prices\n",
       "37                     Drum lessons for kids\n",
       "286               Wedding videography prices\n",
       "270                    Video production cost\n",
       "260                      Photographer prices\n",
       "200                   Trim installation cost\n",
       "59                       Voice lesson prices\n",
       "72                  Bathtub refinishing cost\n",
       "275                      Wedding cake prices\n",
       "195                            Termites cost\n",
       "179        Security camera installation cost\n",
       "110    Furnace blower motor replacement cost\n",
       "32                         CPR training cost\n",
       "208                        Weed control cost\n",
       "79                    Carpet cleaning prices\n",
       "263                             Psychic cost\n",
       "121       Garbage disposal installation cost\n",
       "Name: QUICK, dtype: object"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Bernouili NB--Test data Split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "pipeline_NB = Pipeline([\n",
    "    ('count_vectorizer',   CountVectorizer(stop_words='english')),\n",
    "    ('classifier',         BernoulliNB()) ])\n",
    "\n",
    "pipeline_NB.fit(X_train.values, y_train.values)\n",
    "pipeline_NB.predict(examples)\n",
    "pipeline_NB.predict(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  0  4  0  0  0]\n",
      " [ 0  8  9  0  0  0]\n",
      " [ 0  0 27  0  0  0]\n",
      " [ 0  0 10  0  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  0  5  0  0  0]]\n",
      "F1 score:  0.215100401606\n",
      "\n",
      " clasification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   Business       0.00      0.00      0.00         4\n",
      "     Events       1.00      0.47      0.64        17\n",
      "       Home       0.48      1.00      0.65        27\n",
      "    Lessons       0.00      0.00      0.00        10\n",
      "       Pets       0.00      0.00      0.00         1\n",
      "   Wellness       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.47      0.55      0.44        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\G560667\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classifier__binarize': 0.01, 'count_vectorizer__ngram_range': (1, 1)}"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from  sklearn.grid_search import GridSearchCV\n",
    "parameters = {'count_vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "               'classifier__binarize': (1e-2, 1e-3,0.1,0.0),\n",
    " }\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline_NB, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train.values, y_train.values)\n",
    "gs_clf.predict(examples)\n",
    "predictions=gs_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix (y_test, predictions)\n",
    "print(cm)\n",
    "#print ('Accuracy: ',accuracy_score(y_test, predictions))\n",
    "print ('F1 score: ',f1_score(y_test, predictions,average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,predictions))\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from  sklearn.grid_search import GridSearchCV\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')\n",
    "text_mnb_stemmed = Pipeline([('count_vectorizer', stemmed_count_vect),\n",
    "                      ('tfidf', TfidfTransformer()),\n",
    "                      ('mnb', MultinomialNB(fit_prior=False)),\n",
    " ])\n",
    "\n",
    "parameters = {'count_vectorizer__ngram_range': [(1, 1), (1, 2)],\n",
    "               'tfidf__use_idf': (True, False),\n",
    "              'mnb__alpha': (1e-2, 1e-3),\n",
    " }\n",
    "\n",
    "gs_clf = GridSearchCV(pipeline_tfidf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train.values, y_train.values)\n",
    "gs_clf.predict(examples)\n",
    "predictions=gs_clf.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix (y_test, predictions)\n",
    "print(cm)\n",
    "#print ('Accuracy: ',accuracy_score(y_test, predictions))\n",
    "print ('F1 score: ',f1_score(y_test, predictions,average='macro'))\n",
    "print ('\\n clasification report:\\n', classification_report(y_test,predictions))\n",
    "gs_clf.best_score_\n",
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
